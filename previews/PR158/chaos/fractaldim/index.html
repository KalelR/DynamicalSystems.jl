<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Fractal Dimension · DynamicalSystems.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DynamicalSystems.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DynamicalSystems.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../contents/">Contents</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Dynamical systems</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../ds/general/">Dynamical System Definition</a></li><li><a class="tocitem" href="../../ds/predefined/">Predefined Dynamical Systems</a></li><li><a class="tocitem" href="../../embedding/dataset/">Numerical Data</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">DelayEmbeddings</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../embedding/reconstruction/">Delay Coordinates Embedding</a></li><li><a class="tocitem" href="../../embedding/traditional/">Traditional Optimal Embedding</a></li><li><a class="tocitem" href="../../embedding/unified/">Unified Optimal Embedding</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Entropies</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../entropies/api/">Entropies &amp; Probabilities</a></li><li><a class="tocitem" href="../../entropies/estimators/">Probabilities Estimators</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">RecurrenceAnalysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../rqa/rplots/">Recurrence Plots</a></li><li><a class="tocitem" href="../../rqa/quantification/">Recurrence Quantification Analysis</a></li><li><a class="tocitem" href="../../rqa/windowed/">Windowed RQA</a></li><li><a class="tocitem" href="../../rqa/networks/">Recurrence Networks</a></li></ul></li><li><a class="tocitem" href="../../advanced/">Advanced Documentation</a></li><li><a class="tocitem" href="../../contributors_guide/">Contributor Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Fractal Dimension</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Fractal Dimension</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/DynamicalSystems.jl/blob/master/docs/src/chaos/fractaldim.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Fractal-Dimension"><a class="docs-heading-anchor" href="#Fractal-Dimension">Fractal Dimension</a><a id="Fractal-Dimension-1"></a><a class="docs-heading-anchor-permalink" href="#Fractal-Dimension" title="Permalink"></a></h1><p>There are numerous methods that one can use to calculate a so-called &quot;dimension&quot; of a dataset which in the context of dynamical systems is called the <a href="https://en.wikipedia.org/wiki/Fractal_dimension">Fractal dimension</a>. Several variants of a computationally feasible fractal dimension exist and a simple usage example is shown in the <a href="#Fractal-dimension-example">Fractal dimension example</a> subsection.</p><h2 id="Generalized-dimension"><a class="docs-heading-anchor" href="#Generalized-dimension">Generalized dimension</a><a id="Generalized-dimension-1"></a><a class="docs-heading-anchor-permalink" href="#Generalized-dimension" title="Permalink"></a></h2><p>Based on the definition of the Generalized entropy (<a href="../../entropies/api/#Entropies.genentropy"><code>genentropy</code></a>), one can calculate an appropriate dimension, called <em>generalized dimension</em>:</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.generalized_dim" href="#ChaosTools.generalized_dim"><code>ChaosTools.generalized_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">generalized_dim(dataset [, sizes]; q = 1, base = MathConstants.e) -&gt; Δ_q</code></pre><p>Return the <code>q</code> order generalized dimension of the <code>dataset</code>, by calculating the <a href="../../entropies/api/#Entropies.genentropy"><code>genentropy</code></a> for each <code>ε ∈ sizes</code>.</p><p>The case of <code>q = 0</code> is often called &quot;capacity&quot; or &quot;box-counting&quot; dimension, while <code>q = 1</code> is the &quot;information&quot; dimension.</p><p><strong>Description</strong></p><p>The returned dimension is approximated by the (inverse) power law exponent of the scaling of the <a href="../../entropies/api/#Entropies.genentropy"><code>genentropy</code></a> <span>$H_q$</span> versus the box size <code>ε</code>, where <code>ε ∈ sizes</code>:</p><p class="math-container">\[H_q \sim -\Delta_q\log(\varepsilon)\]</p><p>Calling this function performs a lot of automated steps:</p><ol><li>A vector of box sizes is decided by calling <code>sizes = estimate_boxsizes(dataset)</code>, if <code>sizes</code> is not given.</li><li>For each element of <code>sizes</code> the appropriate entropy is calculated, through <code>H = genentropy.(Ref(dataset), sizes; q, base)</code>. Let <code>x = -log.(sizes)</code>.</li><li>The curve <code>H(x)</code> is decomposed into linear regions, using <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a><code>(x, h)</code>.</li><li>The biggest linear region is chosen, and a fit for the slope of that region is performed using the function <a href="#ChaosTools.linear_region"><code>linear_region</code></a>, which does a simple linear regression fit using <a href="#ChaosTools.linreg"><code>linreg</code></a>. This slope is the return value of <code>generalized_dim</code>.</li></ol><p>By doing these steps one by one yourself, you can adjust the keyword arguments given to each of these function calls, refining the accuracy of the result.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.molteno_dim" href="#ChaosTools.molteno_dim"><code>ChaosTools.molteno_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">molteno_dim(data::Dataset; k0 = 10, q = 1.0, base = ℯ)</code></pre><p>Calculate the generalized dimension using the algorithm for box division defined by Molteno<sup class="footnote-reference"><a id="citeref-Molteno1993" href="#footnote-Molteno1993">[Molteno1993]</a></sup>.</p><p><strong>Description</strong></p><p>Divide the data into boxes with each new box having half the side length of the former box using <a href="#ChaosTools.molteno_boxing"><code>molteno_boxing</code></a>. Break if the number of points over the number of filled boxes falls below <code>k0</code>. Then the generalized dimension can be calculated by using <a href="../../entropies/api/#Entropies.genentropy"><code>genentropy</code></a> to calculate the sum over the logarithm also considering possible approximations and fitting this to the logarithm of one over the boxsize using <a href="#ChaosTools.linear_region"><code>linear_region</code></a>.</p><p>This algorithm is faster than the traditional approach of using <a href="../../entropies/api/#Entropies.probabilities"><code>probabilities</code></a>, but it is only suited for low dimensional data since it divides each box into <code>2^D</code> new boxes if <code>D</code> is the dimension. For large <code>D</code> this leads to low numbers of box divisions before the threshold is passed and the divison stops. This results to a low number of data points to fit the dimension to and thereby a poor estimate.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.molteno_boxing" href="#ChaosTools.molteno_boxing"><code>ChaosTools.molteno_boxing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">molteno_boxing(data::Dataset; k0 = 10) → (probs, εs)</code></pre><p>Distribute the <code>data</code> into boxes whose size is halved in each step. Stop if the average number of points per filled box falls below the threshold <code>k0</code>.</p><p>Return <code>probs</code>, a vector of <code>Propabilities</code> for different box sizes and the corresponding box sizes <code>εs</code>.</p><p><strong>Description</strong></p><p>Project the <code>data</code> onto the whole interval of numbers that is covered by <code>UInt64</code>. This projected data is distributed into boxes whose size decreases by factor 2 in each step. For each box that contains more than one point <code>2^D</code> new boxes are created where <code>D</code> is the dimension of the data.</p><p>The process of dividing the data into new boxes stops when the number of points over the number of filled boxes falls below <code>k0</code>. The box sizes <code>εs</code> are calculated and returned together with the <code>probs</code>.</p><p>See<sup class="footnote-reference"><a id="citeref-Molteno1993" href="#footnote-Molteno1993">[Molteno1993]</a></sup> for more.</p></div></section></article><div class="admonition is-danger"><header class="admonition-header">Be wary when using `generalized_dim`</header><div class="admonition-body"><p>As stated clearly by the documentation string, calling <code>generalized_dim</code> performs a lot of automated steps by calling other functions (see below) with default arguments. It is actually more like a convenient bundle than an actual function and therefore you should be careful when considering the validity of the returned number.</p></div></div><h2 id="Fractal-dimension-example"><a class="docs-heading-anchor" href="#Fractal-dimension-example">Fractal dimension example</a><a id="Fractal-dimension-example-1"></a><a class="docs-heading-anchor-permalink" href="#Fractal-dimension-example" title="Permalink"></a></h2><p>For an example of using entropies to compute the dimension of an attractor let&#39;s use everyone&#39;s favorite system:</p><pre><code class="language- hljs">using DynamicalSystems, PyPlot
lor = Systems.lorenz()</code></pre><p>Our goal is to compute entropies for many different partition sizes <code>ε</code>, so let&#39;s get down to it:</p><pre><code class="language- hljs">tr = trajectory(lor, 100.0; Ttr = 10.0)

ες = ℯ .^ (-3.5:0.5:3.5) # semi-random guess
Hs = genentropy.(Ref(tr), ες; q = 1)</code></pre><pre><code class="language- hljs">xs = @. -log(ες)
fig = figure()
plot(xs, Hs)
ylabel(&quot;\$H_1\$&quot;)
xlabel(&quot;\$-\\log (\\epsilon)\$&quot;);
fig.tight_layout(pad=0.3); fig</code></pre><p>The slope of the linear scaling region of the above plot is the generalized dimension (of order q = 1) for the attractor of the Lorenz system.</p><p>Given that we <em>see</em> the plot, we can estimate where the linear scaling region starts and ends. However, we can use the function <a href="#ChaosTools.linear_region"><code>linear_region</code></a> to get an estimate of the result as well. First let&#39;s visualize what it does:</p><pre><code class="language- hljs">lrs, slopes = linear_regions(xs, Hs, tol = 0.25)

fig = figure()
for i in 1:length(lrs)-1
    plot(xs[lrs[i]:lrs[i+1]], Hs[lrs[i]:lrs[i+1]], marker = &quot;o&quot;)
end
ylabel(&quot;\$H_1\$&quot;)
xlabel(&quot;\$-\\log (\\epsilon)\$&quot;);
fig.tight_layout(pad=0.3); fig</code></pre><p>The <a href="#ChaosTools.linear_region"><code>linear_region</code></a> function  computes the slope of the largest region:</p><pre><code class="language- hljs">Δ = linear_region(xs, Hs)[2]</code></pre><p>This result is an approximation of the information dimension (because we used <code>q = 1</code>) of the Lorenz attractor.</p><hr/><p>The above pipeline is bundled in <a href="#ChaosTools.generalized_dim"><code>generalized_dim</code></a>. For example, the dimension of the strange attractor of the <a href="../../ds/predefined/#DynamicalSystemsBase.Systems.henon"><code>Systems.henon</code></a> map, following the above approach but taking automated steps, is:</p><pre><code class="language-julia hljs">using DynamicalSystems
hen = Systems.henon()
tr = trajectory(hen, 200000)
D_hen = generalized_dim(tr; q = 1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.221186840581862</code></pre><p>As a side note, be sure that you have enough data points, otherwise the values you will get will never be correct, as is demonstrated by J.-P. Eckmann and D. Ruelle (see Physica D <strong>56</strong>, pp 185-187 (1992)).</p><h2 id="Linear-scaling-regions"><a class="docs-heading-anchor" href="#Linear-scaling-regions">Linear scaling regions</a><a id="Linear-scaling-regions-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-scaling-regions" title="Permalink"></a></h2><p>And other utilities, especially <a href="#ChaosTools.linreg"><code>linreg</code></a>, used in both [<code>generalized_dim</code>] and <a href="#ChaosTools.grassberger_dim"><code>grassberger_dim</code></a>.</p><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linear_regions" href="#ChaosTools.linear_regions"><code>ChaosTools.linear_regions</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">linear_regions(x, y; dxi::Int = 1, tol = 0.25) -&gt; (lrs, tangents)</code></pre><p>Identify regions where the curve <code>y(x)</code> is linear, by scanning the <code>x</code>-axis every <code>dxi</code> indices sequentially (e.g. at <code>x[1] to x[5], x[5] to x[10], x[10] to x[15]</code> and so on if <code>dxi=5</code>).</p><p>If the slope (calculated via linear regression) of a region of width <code>dxi</code> is approximatelly equal to that of the previous region, within tolerance <code>tol</code>, then these two regions belong to the same linear region.</p><p>Return the indices of <code>x</code> that correspond to linear regions, <code>lrs</code>, and the <em>correct</em> <code>tangents</code> at each region (obtained via a second linear regression at each accumulated region).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linear_region" href="#ChaosTools.linear_region"><code>ChaosTools.linear_region</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">linear_region(x, y; kwargs...) -&gt; ((ind1, ind2), slope)</code></pre><p>Call <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a> and identify and return the largest linear region and its slope. The region starts and stops at <code>x[ind1:ind2]</code>.</p><p>The keywords <code>dxi, tol</code> are propagated as-is to <a href="#ChaosTools.linear_regions"><code>linear_regions</code></a>. The keyword <code>ignore_saturation = true</code> ignores saturation that (sometimes) happens at the start and end of the curve <code>y(x)</code>, where the curve flattens. The keyword <code>sat = 0.01</code> decides what saturation is (while <code>abs(y[i]-y[i+1])&lt;sat</code> we  are in a saturation regime).</p><p>The keyword <code>warning = true</code> prints a warning if the linear region is less than 1/3 of the available x-axis.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.linreg" href="#ChaosTools.linreg"><code>ChaosTools.linreg</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">linreg(x, y) -&gt; a, b</code></pre><p>Perform a linear regression to find the best coefficients so that the curve: <code>z = a + b*x</code> has the least squared error with <code>y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.estimate_boxsizes" href="#ChaosTools.estimate_boxsizes"><code>ChaosTools.estimate_boxsizes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate_boxsizes(A::Dataset; kwargs...) → εs</code></pre><p>Return <code>k</code> exponentially spaced values: <code>εs = base .^ range(lower + w, upper + z; length = k)</code>, that are a good estimate for sizes ε that are used in calculating a <a href="#Fractal-Dimension">Fractal Dimension</a>. It is strongly recommended to <a href="chaos/@ref"><code>standardize</code></a> input dataset <code>A</code> before using this function.</p><p>Let <code>d₋</code> be the minimum pair-wise distance in <code>A</code> and <code>d₊</code> the average total length of <code>A</code> along each of the dimensions of <code>A</code>. Then <code>lower = log(base, d₋)</code> and <code>upper = log(base, d₊)</code>. Because by default <code>w=1, z=-1</code>, the returned sizes are an order of mangitude larger than the minimum distance, and an order of magnitude smaller than the maximum distance.</p><p><strong>Keywords</strong></p><ul><li><code>w = 1, z = -1, k = 20</code> : as explained above.</li><li><code>base = MathConstants.e</code> : the base used in the <code>log</code> function.</li><li><code>warning = true</code>: Print some warnings for bad estimates.</li><li><code>autoexpand = true</code>: If the final estimated range does not cover at least 2 orders of magnitude, it is automatically expanded by setting <code>w -= we</code> and <code>z -= ze</code>. You can set different default values to the keywords <code>we = w, ze = z</code>.</li></ul></div></section></article><h2 id="Correlation-sum-based-dimension"><a class="docs-heading-anchor" href="#Correlation-sum-based-dimension">Correlation sum based dimension</a><a id="Correlation-sum-based-dimension-1"></a><a class="docs-heading-anchor-permalink" href="#Correlation-sum-based-dimension" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.correlationsum" href="#ChaosTools.correlationsum"><code>ChaosTools.correlationsum</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">correlationsum(X, ε::Real; w = 0, norm = Euclidean(), q = 2) → C_q(ε)</code></pre><p>Calculate the <code>q</code>-order correlation sum of <code>X</code> (<code>Dataset</code> or timeseries) for a given radius <code>ε</code> and <code>norm</code>. They keyword <code>show_progress = false</code> can be used to display a progress bar for large <code>X</code>.</p><p>The function <a href="#ChaosTools.boxed_correlationsum"><code>boxed_correlationsum</code></a> is faster and should be preferred over this one.</p><p><strong>Description</strong></p><p>The correlation sum is done using the formula:</p><p class="math-container">\[C_2(\epsilon) = \frac{2}{(N-w)(N-w-1)}\sum_{i=1}^{N}\sum_{j=1+w+i}^{N} B(||X_i - X_j|| &lt; \epsilon)\]</p><p>for <code>q=2</code> and</p><p class="math-container">\[C_q(\epsilon) = \left[\frac{1}{\alpha} \sum_{i=w+1}^{N-w}\left[\sum_{j:|i-j| &gt; w} B(||X_i - X_j|| &lt; \epsilon)\right]^{q-1}\right]^{1/(q-1)}\]</p><p>where</p><p class="math-container">\[\alpha = (N-2w)(N-2w-1)^{(q-1)}\]</p><p>for <code>q≠2</code>, where <span>$N$</span> is its length and <span>$B$</span> gives 1 if the argument is <code>true</code>. <code>w</code> is the <a href="../../embedding/dataset/#Theiler-window">Theiler window</a>. If <code>ε</code> is a vector its values have to be ordered. See the article of Grassberger for the general definition <sup class="footnote-reference"><a id="citeref-Grassberger2007" href="#footnote-Grassberger2007">[Grassberger2007]</a></sup> and the book &quot;Nonlinear Time Series Analysis&quot; <sup class="footnote-reference"><a id="citeref-Kantz2003" href="#footnote-Kantz2003">[Kantz2003]</a></sup>, Ch. 6, for a discussion around <code>w</code> and choosing best values and Ch. 11.3 for the explicit definition of the q-order correlationsum.</p><pre><code class="nohighlight hljs">correlationsum(X, εs::AbstractVector; w, norm, q) → C_q(ε)</code></pre><p>If <code>εs</code> is a vector, <code>C_q</code> is calculated for each <code>ε ∈ εs</code>. If also <code>q=2</code>, we attempt to do further optimizations are done, if the allocation a matrix of size <code>N×N</code> is possible</p><p>See <a href="chaos/@ref"><code>grassberger</code></a> for more. See also <a href="#ChaosTools.takens_best_estimate"><code>takens_best_estimate</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.grassberger_dim" href="#ChaosTools.grassberger_dim"><code>ChaosTools.grassberger_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">grassberger_dim(data, εs = estimate_boxsizes(data); kwargs...) → D_C</code></pre><p>Use the method of Grassberger and Proccacia<sup class="footnote-reference"><a id="citeref-Grassberger1983" href="#footnote-Grassberger1983">[Grassberger1983]</a></sup>, and the correction by Theiler<sup class="footnote-reference"><a id="citeref-Theiler1986" href="#footnote-Theiler1986">[Theiler1986]</a></sup>, to estimate the correlation dimension <code>D_C</code> of the given <code>data</code>.</p><p>This function does something extremely simple:</p><pre><code class="language-julia hljs">cm = correlationsum(data, εs; kwargs...)
return linear_region(log.(sizes), log(cm))[2]</code></pre><p>i.e. it calculates <a href="#ChaosTools.correlationsum"><code>correlationsum</code></a> for various radii and then tries to find a linear region in the plot of the log of the correlation sum versus log(ε). See <a href="#ChaosTools.generalized_dim"><code>generalized_dim</code></a> for a more thorough explanation.</p><p>See also <a href="#ChaosTools.takens_best_estimate"><code>takens_best_estimate</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.boxed_correlationsum" href="#ChaosTools.boxed_correlationsum"><code>ChaosTools.boxed_correlationsum</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">boxed_correlationsum(X::Dataset, εs, r0 = maximum(εs); kwargs...) → Cs</code></pre><p>Estimate the box assisted q-order correlation sum<sup class="footnote-reference"><a id="citeref-Kantz2003" href="#footnote-Kantz2003">[Kantz2003]</a></sup> <code>Cs</code> out of a dataset <code>X</code> for each radius in <code>εs</code>, by splitting the data into boxes of size <code>r0</code> beforehand. This method is much faster than <a href="#ChaosTools.correlationsum"><code>correlationsum</code></a>, <strong>provided that</strong> the  box size <code>r0</code> is significantly smaller than then the attractor length. A good estimate for <code>r0</code> is <a href="#ChaosTools.estimate_r0_buenoorovio"><code>estimate_r0_buenoorovio</code></a>.</p><pre><code class="nohighlight hljs">boxed_correlationsum(X; kwargs...) → εs, Cs</code></pre><p>In this method the minimum inter-point distance and <a href="#ChaosTools.estimate_r0_buenoorovio"><code>estimate_r0_buenoorovio</code></a> are used to estimate good <code>εs</code> for the calculation, which are also returned.</p><p><strong>Keywords</strong></p><ul><li><code>q = 2</code></li><li><code>P = autoprismdim(data)</code> : The prism dimension.</li><li><code>w = 0</code> : The <a href="../../embedding/dataset/#Theiler-window">Theiler window</a>.</li><li><code>show_progress = false</code> : Whether to display a progress bar for the calculation.</li></ul><p><strong>Description</strong></p><p><code>C_q(ε)</code> is calculated for every <code>ε ∈ εs</code> and each of the boxes to then be summed up afterwards. The method of splitting the data into boxes was  implemented according to Theiler<sup class="footnote-reference"><a id="citeref-Theiler1987" href="#footnote-Theiler1987">[Theiler1987]</a></sup>. <code>w</code> is the <a href="../../embedding/dataset/#Theiler-window">Theiler window</a>. <code>P</code> is the prism dimension. If <code>P</code> is unequal to the dimension of the data, only the first <code>P</code> dimensions are considered for the box distribution (this is called the prism-assisted version). By default <code>P</code> is choosen automatically.</p><p>The function is explicitly optimized for <code>q = 2</code> but becomes quite slow for <code>q ≠ 2</code>.</p><p>See <a href="#ChaosTools.correlationsum"><code>correlationsum</code></a> for the definition of <code>C_q</code> and also <a href="#ChaosTools.data_boxing"><code>data_boxing</code></a> to use the algorithm that splits data into boxes.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.data_boxing" href="#ChaosTools.data_boxing"><code>ChaosTools.data_boxing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">data_boxing(data, r0, P) → boxes, contents</code></pre><p>Distribute the <code>data</code> points into boxes of size <code>r0</code>. Return box positions and the contents of each box as two separate vectors. Implemented according to the paper by Theiler<sup class="footnote-reference"><a id="citeref-Theiler1987" href="#footnote-Theiler1987">[Theiler1987]</a></sup> improving the algorithm by Grassberger and Procaccia<sup class="footnote-reference"><a id="citeref-Grassberger1983" href="#footnote-Grassberger1983">[Grassberger1983]</a></sup>. If <code>P</code> is smaller than the dimension of the data, only the first <code>P</code> dimensions are considered for the distribution into boxes.</p><p>See also: <a href="#ChaosTools.boxed_correlationsum"><code>boxed_correlationsum</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.estimate_r0_buenoorovio" href="#ChaosTools.estimate_r0_buenoorovio"><code>ChaosTools.estimate_r0_buenoorovio</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate_r0_buenoorovio(X::Dataset, P = autoprismdim(X))</code></pre><p>Estimates a reasonable size for boxing the time series <code>X</code> proposed by Bueno-Orovio and Pérez-García<sup class="footnote-reference"><a id="citeref-Bueno2007" href="#footnote-Bueno2007">[Bueno2007]</a></sup> before calculating the correlation dimension as presented by Theiler<sup class="footnote-reference"><a id="citeref-Theiler1983" href="#footnote-Theiler1983">[Theiler1983]</a></sup>. If instead of boxes, prisms are chosen everything stays the same but <code>P</code> is the dimension of the prism. To do so the dimension <code>ν</code> is estimated by running the algorithm by Grassberger and Procaccia<sup class="footnote-reference"><a id="citeref-Grassberger1983" href="#footnote-Grassberger1983">[Grassberger1983]</a></sup> with <code>√N</code> points where <code>N</code> is the number of total data points. An effective size <code>ℓ</code> of the attractor is calculated by boxing a small subset of size <code>N/10</code> into boxes of sidelength <code>r_ℓ</code> and counting the number of filled boxes <code>η_ℓ</code>.</p><p class="math-container">\[\ell = r_\ell \eta_\ell ^{1/\nu}\]</p><p>The optimal number of filled boxes <code>η_opt</code> is calculated by minimising the number of calculations.</p><p class="math-container">\[\eta_\textrm{opt} = N^{2/3}\cdot \frac{3^\nu - 1}{3^P - 1}^{1/2}.\]</p><p><code>P</code> is the dimension of the data or the number of edges on the prism that don&#39;t span the whole dataset.</p><p>Then the optimal boxsize <span>$r_0$</span> computes as</p><p class="math-container">\[r_0 = \ell / \eta_\textrm{opt}^{1/\nu}.\]</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.estimate_r0_theiler" href="#ChaosTools.estimate_r0_theiler"><code>ChaosTools.estimate_r0_theiler</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate_r0_theiler(X::Dataset) → r0, ε0</code></pre><p>Estimate a reasonable size for boxing the data <code>X</code> before calculating the <a href="#ChaosTools.boxed_correlationsum"><code>boxed_correlationsum</code></a> proposed by Theiler<sup class="footnote-reference"><a id="citeref-Theiler1987" href="#footnote-Theiler1987">[Theiler1987]</a></sup>. Return the boxing size <code>r0</code> and minimum inter-point distance in <code>X</code>, <code>ε0</code>.</p><p>To do so the dimension is estimated by running the algorithm by Grassberger and Procaccia<sup class="footnote-reference"><a id="citeref-Grassberger1983" href="#footnote-Grassberger1983">[Grassberger1983]</a></sup> with <code>√N</code> points where <code>N</code> is the number of total data points. Then the optimal boxsize <span>$r_0$</span> computes as</p><p class="math-container">\[r_0 = R (2/N)^{1/\nu}\]</p><p>where <span>$R$</span> is the size of the chaotic attractor and <span>$\nu$</span> is the estimated dimension.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.correlationsum_fixedmass" href="#ChaosTools.correlationsum_fixedmass"><code>ChaosTools.correlationsum_fixedmass</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">correlationsum_fixedmass(data, max_j; metric = Euclidean(), M = length(data)) → rs, ys</code></pre><p>A fixed mass algorithm for the calculation of the fractal dimension <span>$\Delta$</span> according to <sup class="footnote-reference"><a id="citeref-Grassberger1988" href="#footnote-Grassberger1988">[Grassberger1988]</a></sup> with <code>max_j</code> the maximum number of neighbours that should be considered for the calculation, <code>M</code> defines the number of points considered for the calculation, default is the whole data set.</p><p>Implements</p><p class="math-container">\[\Delta \overline{\log r^{(j)}} \sim Ψ(j) - \log N\]</p><p>where <span>$\Psi(j) = \frac{\text{d} \log Γ(j)}{\text{d} j}$</span>, <code>rs</code> = <span>$\overline{\log r^{(j)}}$</span> and <code>ys</code> = <span>$\Psi(j) - \log N$</span>.</p><p><span>$\Delta$</span> can be computed by using <code>linear_region(rs, ys)</code>.</p></div></section></article><h2 id="Takens&#39;-best-estimate"><a class="docs-heading-anchor" href="#Takens&#39;-best-estimate">Takens&#39; best estimate</a><a id="Takens&#39;-best-estimate-1"></a><a class="docs-heading-anchor-permalink" href="#Takens&#39;-best-estimate" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.takens_best_estimate" href="#ChaosTools.takens_best_estimate"><code>ChaosTools.takens_best_estimate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">takens_best_estimate(X, εmax, metric = Chebyshev(),εmin = 0) → D_C, D_C_95u, D_C_95l</code></pre><p>Use the so-called &quot;Takens&#39; best estimate&quot; <sup class="footnote-reference"><a id="citeref-Takens1985" href="#footnote-Takens1985">[Takens1985]</a></sup><sup class="footnote-reference"><a id="citeref-Theiler1988" href="#footnote-Theiler1988">[Theiler1988]</a></sup> method for estimating the correlation dimension <code>D_C</code> and the upper (<code>D_C_95u</code>) and lower (<code>D_C_95l</code>) confidence limit for the given dataset <code>X</code>.</p><p>The original formula is</p><p class="math-container">\[D_C \approx \frac{C(\epsilon_\text{max})}{\int_0^{\epsilon_\text{max}}(C(\epsilon) / \epsilon) \, d\epsilon}\]</p><p>where <span>$C$</span> is the <a href="#ChaosTools.correlationsum"><code>correlationsum</code></a> and <span>$\epsilon_\text{max}$</span> is an upper cutoff. Here we use the later expression</p><p class="math-container">\[D_C \approx - \frac{1}{\eta},\quad \eta = \frac{1}{(N-1)^*}\sum_{[i, j]^*}\log(||X_i - X_j|| / \epsilon_\text{max})\]</p><p>where the sum happens for all <span>$i, j$</span> so that <span>$i &lt; j$</span> and <span>$||X_i - X_j|| &lt; \epsilon_\text{max}$</span>. In the above expression, the bias in the original paper has already been corrected, as suggested in <sup class="footnote-reference"><a id="citeref-Borovkova1999" href="#footnote-Borovkova1999">[Borovkova1999]</a></sup>.</p><p>The confidence limits are estimated from the log-likelihood function by finding the values of <code>D_C</code> where the function has fallen by 2 from its maximum, see e.g. <sup class="footnote-reference"><a id="citeref-Barlow" href="#footnote-Barlow">[Barlow]</a></sup> chapter 5.3 Because the CLT does not apply (no independent measurements), the limits are not neccesarily symmetric.</p><p>According to <sup class="footnote-reference"><a id="citeref-Borovkova1999" href="#footnote-Borovkova1999">[Borovkova1999]</a></sup>, introducing a lower cutoff <code>εmin</code> can make the algorithm more stable (no divergence), this option is given but defaults to zero.</p><p>If <code>X</code> comes from a delay coordinates embedding of a timseries <code>x</code>, a recommended value for <span>$\epsilon_\text{max}$</span> is <code>std(x)/4</code>.</p></div></section></article><h2 id="Kaplan-Yorke-Dimension"><a class="docs-heading-anchor" href="#Kaplan-Yorke-Dimension">Kaplan-Yorke Dimension</a><a id="Kaplan-Yorke-Dimension-1"></a><a class="docs-heading-anchor-permalink" href="#Kaplan-Yorke-Dimension" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ChaosTools.kaplanyorke_dim" href="#ChaosTools.kaplanyorke_dim"><code>ChaosTools.kaplanyorke_dim</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kaplanyorke_dim(λs::AbstractVector)</code></pre><p>Calculate the Kaplan-Yorke dimension, a.k.a. Lyapunov dimension<sup class="footnote-reference"><a id="citeref-Kaplan1970" href="#footnote-Kaplan1970">[Kaplan1970]</a></sup>.</p><p><strong>Description</strong></p><p>The Kaplan-Yorke dimension is simply the point where <code>cumsum(λs)</code> becomes zero (interpolated):</p><p class="math-container">\[ D_{KY} = k + \frac{\sum_{i=1}^k \lambda_i}{|\lambda_{k+1}|},\quad k = \max_j \left[ \sum_{i=1}^j \lambda_i &gt; 0 \right].\]</p><p>If the sum of the exponents never becomes negative the function will return the length of the input vector.</p><p>Useful in combination with <a href="../lyapunovs/#ChaosTools.lyapunovspectrum"><code>lyapunovspectrum</code></a>.</p></div></section></article><p>Notice that calling this function requires you to pass the Lyapunov exponents in an ordered vector form (largest to smallest). Example:</p><pre><code class="language-julia hljs">using DynamicalSystems
hen = Systems.henon()
D_kp = kaplanyorke_dim(lyapunovspectrum(hen, 100000))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.2587014767953524</code></pre><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Molteno1993"><a class="tag is-link" href="#citeref-Molteno1993">Molteno1993</a>Molteno, T. C. A., <a href="https://doi.org/10.1103/PhysRevE.48.R3263">Fast O(N) box-counting algorithm for estimating dimensions. Phys. Rev. E 48, R3263(R) (1993)</a></li><li class="footnote" id="footnote-Grassberger"><a class="tag is-link" href="#citeref-Grassberger">Grassberger</a>Peter Grassberger (2007) <a href="http://dx.doi.org/10.4249/scholarpedia.3043">Grassberger-Procaccia algorithm. Scholarpedia, 2(5):3043.</a></li><li class="footnote" id="footnote-Kantz"><a class="tag is-link" href="#citeref-Kantz">Kantz</a>Kantz, H., &amp; Schreiber, T. (2003). <a href="https://doi:10.1017/CBO9780511755798.013">More about invariant quantities. In Nonlinear Time Series Analysis (pp. 197-233). Cambridge: Cambridge University Press.</a></li><li class="footnote" id="footnote-Grassberger1983"><a class="tag is-link" href="#citeref-Grassberger1983">Grassberger1983</a>Grassberger and Proccacia, <a href="https://journals-aps-org.e-bis.mpimet.mpg.de/prl/abstract/10.1103/PhysRevLett.50.346">Characterization of strange attractors, PRL 50 (1983)</a></li><li class="footnote" id="footnote-Theiler1986"><a class="tag is-link" href="#citeref-Theiler1986">Theiler1986</a>Theiler, <a href="https://doi.org/10.1103/PhysRevA.34.2427">Spurious dimension from correlation algorithms applied to limited time-series data. Physical Review A, 34</a></li><li class="footnote" id="footnote-Kantz"><a class="tag is-link" href="#citeref-Kantz">Kantz</a>Kantz, H., &amp; Schreiber, T. (2003). <a href="https://doi:10.1017/CBO9780511755798.013">More about invariant quantities. In Nonlinear Time Series Analysis (pp. 197-233). Cambridge: Cambridge University Press.</a></li><li class="footnote" id="footnote-Theiler1987"><a class="tag is-link" href="#citeref-Theiler1987">Theiler1987</a>Theiler, <a href="https://doi.org/10.1103/PhysRevA.36.4456">Efficient algorithm for estimating the correlation dimension from a set of discrete points. Physical Review A, 36</a></li><li class="footnote" id="footnote-Theiler1987"><a class="tag is-link" href="#citeref-Theiler1987">Theiler1987</a>Theiler, <a href="https://doi.org/10.1103/PhysRevA.36.4456">Efficient algorithm for estimating the correlation dimension from a set of discrete points. Physical Review A, 36</a></li><li class="footnote" id="footnote-Grassberger1983"><a class="tag is-link" href="#citeref-Grassberger1983">Grassberger1983</a>Grassberger and Proccacia, <a href="https://journals-aps-org.e-bis.mpimet.mpg.de/prl/abstract/10.1103/PhysRevLett.50.346">Characterization of strange attractors, PRL 50 (1983)</a></li><li class="footnote" id="footnote-Bueno2007"><a class="tag is-link" href="#citeref-Bueno2007">Bueno2007</a>Bueno-Orovio and Pérez-García, <a href="https://doi.org/10.1016/j.chaos.2006.03.043">Enhanced box and prism assisted algorithms for computing the correlation dimension. Chaos Solitons &amp; Fractrals, 34(5)</a></li><li class="footnote" id="footnote-Theiler1987"><a class="tag is-link" href="#citeref-Theiler1987">Theiler1987</a>Theiler, <a href="https://doi.org/10.1103/PhysRevA.36.4456">Efficient algorithm for estimating the correlation dimension from a set of discrete points. Physical Review A, 36</a></li><li class="footnote" id="footnote-Grassberger1983"><a class="tag is-link" href="#citeref-Grassberger1983">Grassberger1983</a>Grassberger and Proccacia, <a href="https://journals-aps-org.e-bis.mpimet.mpg.de/prl/abstract/10.1103/PhysRevLett.50.346">Characterization of strange attractors, PRL 50 (1983)</a></li><li class="footnote" id="footnote-Theiler1987"><a class="tag is-link" href="#citeref-Theiler1987">Theiler1987</a>Theiler, <a href="https://doi.org/10.1103/PhysRevA.36.4456">Efficient algorithm for estimating the correlation dimension from a set of discrete points. Physical Review A, 36</a></li><li class="footnote" id="footnote-Grassberger1983"><a class="tag is-link" href="#citeref-Grassberger1983">Grassberger1983</a>Grassberger and Proccacia, <a href="https://journals-aps-org.e-bis.mpimet.mpg.de/prl/abstract/10.1103/PhysRevLett.50.346">Characterization of strange attractors, PRL 50 (1983)</a></li><li class="footnote" id="footnote-Grassberger1988"><a class="tag is-link" href="#citeref-Grassberger1988">Grassberger1988</a>Peter Grassberger (1988) <a href="https://doi.org/10.1016/0375-9601(88)90193-4">Finite sample Corrections to Entropy and Dimension Estimates, Physics Letters A 128(6-7)</a></li><li class="footnote" id="footnote-Takens1985"><a class="tag is-link" href="#citeref-Takens1985">Takens1985</a>Takens, On the numerical determination of the dimension of an attractor, in: B.H.W. Braaksma, B.L.J.F. Takens (Eds.), Dynamical Systems and Bifurcations, in: Lecture Notes in Mathematics, Springer, Berlin, 1985, pp. 99–106.</li><li class="footnote" id="footnote-Theiler1988"><a class="tag is-link" href="#citeref-Theiler1988">Theiler1988</a>Theiler, <a href="https://doi.org/10.1016/0375-9601(88)91016-X">Lacunarity in a best estimator of fractal dimension. Physics Letters A, 133(4–5)</a></li><li class="footnote" id="footnote-Borovkova1999"><a class="tag is-link" href="#citeref-Borovkova1999">Borovkova1999</a>Borovkova et al., <a href="https://doi.org/10.1214/aoap/1029962747">Consistency of the Takens estimator for the correlation dimension. The Annals of Applied Probability, 9, 05 1999.</a></li><li class="footnote" id="footnote-Barlow"><a class="tag is-link" href="#citeref-Barlow">Barlow</a>Barlow, R., Statistics - A Guide to the Use of Statistical Methods in the Physical Sciences. Vol 29. John Wiley &amp; Sons, 1993</li><li class="footnote" id="footnote-Kaplan1970"><a class="tag is-link" href="#citeref-Kaplan1970">Kaplan1970</a>J. Kaplan &amp; J. Yorke, <em>Chaotic behavior of multidimensional difference equations</em>, Lecture Notes in Mathematics vol. <strong>730</strong>, Springer (1979)</li></ul></section></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Saturday 4 December 2021 20:51">Saturday 4 December 2021</span>. Using Julia version 1.7.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
